{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d62be42-239c-4205-988c-8d398aace10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/shreyas/anaconda3/envs/delta/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/shreyas/anaconda3/envs/delta/lib/python3.9/site-packages (from pandas) (1.23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/shreyas/anaconda3/envs/delta/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/shreyas/anaconda3/envs/delta/lib/python3.9/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/shreyas/anaconda3/envs/delta/lib/python3.9/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/shreyas/anaconda3/envs/delta/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: numpy in /home/shreyas/anaconda3/envs/delta/lib/python3.9/site-packages (1.23.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3179231f-a6f5-4244-955e-9651535c0adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from smpl.smpl_numpy import SMPL \n",
    "\n",
    "smpl_model = SMPL(sex='neutral', model_dir='assets/SMPL_NEUTRAL.pkl')\n",
    "# v_sel = smpl_model.vertex_joint_selector \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba947a1f-f9ac-478f-8a6e-2afaddb1e2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "num_betas=10, shapedirs.shape=(6890, 3, 10), self.SHAPE_SPACE_DIM=300\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m shape_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Generate the 3D mesh\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43msmpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbetas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody_pose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpose_tensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_orient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpose_tensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# If `output` contains more than two values, we unpack them all:\u001b[39;00m\n\u001b[1;32m     22\u001b[0m vertices, joints, \u001b[38;5;241m*\u001b[39mother_outputs \u001b[38;5;241m=\u001b[39m output\n",
      "File \u001b[0;32m~/Documents/Disseration/GauHuman/smplx/body_models.py:378\u001b[0m, in \u001b[0;36mSMPL.forward\u001b[0;34m(self, betas, body_pose, global_orient, transl, return_verts, return_full_pose, pose2rot, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m     num_repeats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(batch_size \u001b[38;5;241m/\u001b[39m betas\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    376\u001b[0m     betas \u001b[38;5;241m=\u001b[39m betas\u001b[38;5;241m.\u001b[39mexpand(num_repeats, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 378\u001b[0m vertices, joints \u001b[38;5;241m=\u001b[39m lbs(betas, full_pose, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_template,\n\u001b[1;32m    379\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshapedirs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposedirs,\n\u001b[1;32m    380\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mJ_regressor, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparents,\n\u001b[1;32m    381\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlbs_weights, pose2rot\u001b[38;5;241m=\u001b[39mpose2rot)\n\u001b[1;32m    383\u001b[0m joints \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvertex_joint_selector(vertices, joints)\n\u001b[1;32m    384\u001b[0m \u001b[38;5;66;03m# Map the joints to the current dataset\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from smplx import SMPL\n",
    "import trimesh\n",
    "\n",
    "# Load SMPL model\n",
    "model_path = 'assets/SMPL_NEUTRAL.pkl'  # Replace with the path to your SMPL model\n",
    "smpl = SMPL(model_path, gender='male', batch_size=1)\n",
    "\n",
    "# Set random pose and shape parameters\n",
    "pose = np.zeros((1, 72))  # Pose parameters\n",
    "shape = np.zeros((1, 10))  # Shape parameters\n",
    "\n",
    "# Convert NumPy arrays to PyTorch tensors\n",
    "pose_tensor = torch.tensor(pose, dtype=torch.float32)\n",
    "shape_tensor = torch.tensor(shape, dtype=torch.float32)\n",
    "\n",
    "# Generate the 3D mesh\n",
    "output = smpl.forward(betas=shape_tensor, body_pose=pose_tensor[:, 3:], global_orient=pose_tensor[:, :3])\n",
    "\n",
    "# If `output` contains more than two values, we unpack them all:\n",
    "vertices, joints, *other_outputs = output\n",
    "\n",
    "# Convert the vertices to numpy array\n",
    "vertices = vertices.detach().cpu().numpy().squeeze()\n",
    "\n",
    "# Save as OBJ file using trimesh\n",
    "faces = smpl.faces\n",
    "mesh = trimesh.Trimesh(vertices, faces)\n",
    "mesh.export('smpl_model.obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e41abd9a-313b-47aa-8ed5-7fd09ad266be",
   "metadata": {},
   "outputs": [],
   "source": [
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    # SMPL in canonical space\n",
    "    big_pose_smpl_param = {}\n",
    "    big_pose_smpl_param['R'] = np.eye(3).astype(np.float32)\n",
    "    big_pose_smpl_param['Th'] = np.zeros((1,3)).astype(np.float32)\n",
    "    big_pose_smpl_param['shapes'] = np.zeros((1,10)).astype(np.float32)\n",
    "    big_pose_smpl_param['poses'] = np.zeros((1,72)).astype(np.float32)\n",
    "    big_pose_smpl_param['poses'][0, 5] = 45/180*np.array(np.pi)\n",
    "    big_pose_smpl_param['poses'][0, 8] = -45/180*np.array(np.pi)\n",
    "    big_pose_smpl_param['poses'][0, 23] = -30/180*np.array(np.pi)\n",
    "    big_pose_smpl_param['poses'][0, 26] = 30/180*np.array(np.pi)\n",
    "\n",
    "    big_pose_xyz, x = smpl_model(big_pose_smpl_param['poses'], big_pose_smpl_param['shapes'].reshape(-1))\n",
    "    big_pose_xyz = (np.matmul(big_pose_xyz, big_pose_smpl_param['R'].transpose()) + big_pose_smpl_param['Th']).astype(np.float32)\n",
    "\n",
    "    # obtain the original bounds for point sampling\n",
    "    big_pose_min_xyz = np.min(big_pose_xyz, axis=0)\n",
    "    big_pose_max_xyz = np.max(big_pose_xyz, axis=0)\n",
    "    big_pose_min_xyz -= 0.05\n",
    "    big_pose_max_xyz += 0.05\n",
    "    big_pose_world_bound = np.stack([big_pose_min_xyz, big_pose_max_xyz], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4bc93f0-56a9-47c7-9644-c4a885b2f17a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 0 in argument 0, but got numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Generate the 3D mesh\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43msmpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbetas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbig_pose_smpl_param\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mshapes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody_pose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbig_pose_smpl_param\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mposes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_orient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbig_pose_smpl_param\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mposes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# If `output` contains more than two values, we unpack them all:\u001b[39;00m\n\u001b[1;32m      5\u001b[0m vertices, joints, \u001b[38;5;241m*\u001b[39mother_outputs \u001b[38;5;241m=\u001b[39m output\n",
      "File \u001b[0;32m~/Documents/Disseration/GauHuman/smplx/body_models.py:369\u001b[0m, in \u001b[0;36mSMPL.forward\u001b[0;34m(self, betas, body_pose, global_orient, transl, return_verts, return_full_pose, pose2rot, **kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransl\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    367\u001b[0m     transl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransl\n\u001b[0;32m--> 369\u001b[0m full_pose \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mglobal_orient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody_pose\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(betas\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], global_orient\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    372\u001b[0m                  body_pose\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m betas\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m batch_size:\n",
      "\u001b[0;31mTypeError\u001b[0m: expected Tensor as element 0 in argument 0, but got numpy.ndarray"
     ]
    }
   ],
   "source": [
    "# Convert NumPy arrays to PyTorch tensors\n",
    "pose_tensor = torch.tensor(big_pose_smpl_param['poses'], dtype=torch.float32)\n",
    "shape_tensor = torch.tensor(big_pose_smpl_param['shapes'], dtype=torch.float32)\n",
    "\n",
    "# Generate the 3D mesh\n",
    "output = smpl.forward(betas=shape_tensor, body_pose=pose_tensor[:, 3:], global_orient=pose_tensor[:, :3])\n",
    "\n",
    "\n",
    "# If `output` contains more than two values, we unpack them all:\n",
    "vertices, joints, *other_outputs = output\n",
    "\n",
    "# Convert the vertices to numpy array\n",
    "vertices = vertices.detach().cpu().numpy().squeeze()\n",
    "\n",
    "# Save as OBJ file using trimesh\n",
    "faces = smpl.faces\n",
    "mesh = trimesh.Trimesh(vertices, faces)\n",
    "mesh.export('smpl_model.obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17eff575-abb1-4a0f-804e-759ea98510b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x6890 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 27 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj = 'assets/SMPL_NEUTRAL.pkl'\n",
    "\n",
    "\n",
    "obj_smpl = pd.read_pickle('assets/SMPL_NEUTRAL.pkl')\n",
    "obj_smpl.get('J_regressor')[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebba8505-dbc9-4dc2-8030-8f132669d61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([332, 6260, 2800, 4071, 583])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obj_smpl.get('J')\n",
    "face= {\n",
    "        'nose': 332,\n",
    "        'reye': 6260,\n",
    "        'leye': 2800,\n",
    "        'rear':\t4071,\n",
    "        'lear':\t583,\n",
    "}\n",
    "face.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "900a729a-c6eb-4457-b3a2-2af785066bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 332 6260 2800 4071  583]\n",
      "[[ 0.00242026  0.41171256  0.1370538 ]\n",
      " [-0.03157485  0.44699487  0.09797596]\n",
      " [ 0.03461343  0.4475619   0.09933882]\n",
      " [-0.07265673  0.41884518  0.00539076]\n",
      " [ 0.07415988  0.42008573  0.00802347]] [ 332 6260 2800] [4071  583]\n"
     ]
    }
   ],
   "source": [
    "# obj_smpl.get('J')\n",
    "face= {\n",
    "        'nose': 332,\n",
    "        'reye': 6260,\n",
    "        'leye': 2800,\n",
    "        'rear':\t4071,\n",
    "        'lear':\t583,\n",
    "}\n",
    "# Extract the indices from the face dictionary\n",
    "indices = np.array(list(face.values()))\n",
    "print(indices)\n",
    "# Use the indices to directly get the corresponding rows from big_pose_xyz\n",
    "face_xyz = big_pose_xyz[indices]\n",
    "\n",
    "# Print the result\n",
    "print(face_xyz,indices[0:3],indices[3:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0710a080-536c-4af8-80f8-2a1692627c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3)\n"
     ]
    }
   ],
   "source": [
    "        ###############################**********************########################################## change 2 \n",
    "        \n",
    "        # obtain the original bounds for dense point sampling on the face\n",
    "        xyz_face_min_xyz = np.min(face_xyz, axis=0)\n",
    "        xyz_face_max_xyz = np.max(face_xyz, axis=0)\n",
    "        xyz_face_min_xyz -= 0.05\n",
    "        xyz_face_max_xyz += 0.05\n",
    "        # xyz_face_world_bound = np.stack([xyz_face_min_xyz, xyz_face_max_xyz], axis=0)\n",
    "        \n",
    "\n",
    "        xyz2 = np.append(face_xyz,big_pose_xyz,axis=0)\n",
    "        # xyz2 = np.append(xyz_hand,xyz2,axis=0)\n",
    "\n",
    "        # Define the number of points along each axis (resolution of the grid)\n",
    "        num_points = 10  # For example, 10 points along each axis\n",
    "        \n",
    "        # Create a grid of points within the bounding box\n",
    "        x = np.linspace(xyz_face_min_xyz[0], xyz_face_max_xyz[0], num_points)\n",
    "        y = np.linspace(xyz_face_min_xyz[1], xyz_face_max_xyz[1], num_points)\n",
    "        z = np.linspace(xyz_face_min_xyz[2], xyz_face_max_xyz[2], num_points)\n",
    "\n",
    "        # Generate all combinations of x, y, z\n",
    "        X, Y, Z = np.meshgrid(x, y, z)\n",
    "        # Reshape the grid to get a flat list of 3D points\n",
    "        xyz2 = np.vstack([X.ravel(), Y.ravel(), Z.ravel()]).T\n",
    "        print(xyz2.shape)\n",
    "    \n",
    "        ###############################**********************########################################## change 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13d17f42-67d5-4377-b0f7-9608774d422d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.12265673  0.36171255 -0.04460924]\n",
      " [-0.12265673  0.36171255 -0.0188689 ]\n",
      " [-0.12265673  0.36171255  0.00687144]\n",
      " ...\n",
      " [ 0.12415989  0.4975619   0.13557312]\n",
      " [ 0.12415989  0.4975619   0.16131346]\n",
      " [ 0.12415989  0.4975619   0.1870538 ]]\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "print(xyz2\n",
    "     )\n",
    "\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "af1ea988-5e92-47a9-b06d-4527b4e462b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # obtain the original bounds for point sampling\n",
    "    face_xyz_max_xyz = np.max(face_xyz, axis=0)\n",
    "    face_xyz_min_xyz = np.min(face_xyz, axis=0)\n",
    "    face_xyz_min_xyz -= 0.05\n",
    "    face_xyz_max_xyz += 0.05\n",
    "    face_xyz_world_bound = np.stack([face_xyz_min_xyz, face_xyz_max_xyz], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1c777168-5422-42ac-9158-837fb5654ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.12265673,  0.36171255, -0.04460924],\n",
       "       [ 0.12415989,  0.4975619 ,  0.1870538 ]], dtype=float32)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_xyz_world_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "9a8fcd7b-1763-4371-b5c8-79bac3e298d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz = big_pose_xyz\n",
    "xyz2 = np.append(face_xyz,xyz,axis=0)\n",
    "for x in range(1000):\n",
    "    xyz2 = np.append(face_xyz,xyz2,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "6229dea6-1292-4334-8f52-c23d38333004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6890, 3) (11895, 3) (5, 3)\n"
     ]
    }
   ],
   "source": [
    "print(xyz.shape ,xyz2.shape,face_xyz.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "11f9257f-7170-40d7-973d-f28d492085fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11895"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xyz2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e26643-cf25-4e21-b45a-0194933f01d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:delta]",
   "language": "python",
   "name": "conda-env-delta-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
